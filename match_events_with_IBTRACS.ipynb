{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d0bfe05-4920-4e87-8f68-fb7b6e7f33be",
   "metadata": {},
   "source": [
    "### Match hindcast and observed events with IBTRACS named storms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86b177ce-57e7-4637-a2b5-b4d4d6690589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               event_time     storm_sid storm_name season  basin nature                track_time  storm_lat  storm_lon   dist_km  dt_hours  usa_wind_kt  usa_pres_mb  n_candidates   peak_m\n",
      "1958-09-28 04:00:00+00:00 1958264N17308     HELENE   1958    NaN     TS 1958-09-28 03:00:00+00:00       35.1      -74.9 74.100894       1.0        113.0        944.0             1 4.895494\n",
      "1980-03-25 02:00:00+00:00           NaN        NaN    NaN    NaN    NaN                       NaT        NaN        NaN       NaN       NaN          NaN          NaN             0 4.121277\n",
      "1980-07-04 08:00:00+00:00           NaN        NaN    NaN    NaN    NaN                       NaT        NaN        NaN       NaN       NaN          NaN          NaN             0 4.121277\n",
      "1979-12-02 04:00:00+00:00           NaN        NaN    NaN    NaN    NaN                       NaT        NaN        NaN       NaN       NaN          NaN          NaN             0 4.121277\n",
      "1981-03-27 07:00:00+00:00           NaN        NaN    NaN    NaN    NaN                       NaT        NaN        NaN       NaN       NaN          NaN          NaN             0 4.121277\n",
      "1993-08-31 22:00:00+00:00 1993235N20307      EMILY   1993    NaN     TS 1993-08-31 21:00:00+00:00       35.2      -75.1 54.901713       1.0        100.0        961.0             1 3.705547\n",
      "1985-09-27 07:00:00+00:00 1985260N13336     GLORIA   1985    NaN     TS 1985-09-27 05:30:00+00:00       35.2      -75.6  9.513230       1.5         90.0        942.0             1 3.440969\n",
      "1976-07-11 22:00:00+00:00           NaN        NaN    NaN    NaN    NaN                       NaT        NaN        NaN       NaN       NaN          NaN          NaN             0 3.415065\n",
      "1981-06-16 02:00:00+00:00           NaN        NaN    NaN    NaN    NaN                       NaT        NaN        NaN       NaN       NaN          NaN          NaN             0 3.287051\n",
      "2005-09-15 12:00:00+00:00 2005249N26281    OPHELIA   2005    NaN     TS 2005-09-15 12:00:00+00:00       34.7      -75.8 57.228187       0.0         65.0        984.0             1 3.095963\n",
      "1961-04-13 04:00:00+00:00           NaN        NaN    NaN    NaN    NaN                       NaT        NaN        NaN       NaN       NaN          NaN          NaN             0 2.918101\n",
      "1980-03-03 02:00:00+00:00           NaN        NaN    NaN    NaN    NaN                       NaT        NaN        NaN       NaN       NaN          NaN          NaN             0 2.439597\n",
      "2003-09-18 15:00:00+00:00 2003249N14329     ISABEL   2003    NaN     TS 2003-09-18 17:00:00+00:00       34.9      -76.2 56.698778       2.0         90.0        957.0             1 2.385587\n",
      "1991-08-19 03:00:00+00:00 1991228N26286        BOB   1991    NaN     TS 1991-08-19 03:00:00+00:00       35.5      -74.9 79.801747       0.0         98.0        954.0             1 2.227331\n",
      "1961-02-26 06:00:00+00:00           NaN        NaN    NaN    NaN    NaN                       NaT        NaN        NaN       NaN       NaN          NaN          NaN             0 2.124970\n",
      "1983-03-25 05:00:00+00:00           NaN        NaN    NaN    NaN    NaN                       NaT        NaN        NaN       NaN       NaN          NaN          NaN             0 2.025125\n",
      "1982-10-25 04:00:00+00:00           NaN        NaN    NaN    NaN    NaN                       NaT        NaN        NaN       NaN       NaN          NaN          NaN             0 2.025125\n",
      "1973-02-10 16:00:00+00:00           NaN        NaN    NaN    NaN    NaN                       NaT        NaN        NaN       NaN       NaN          NaN          NaN             0 2.005457\n",
      "1994-11-18 06:00:00+00:00           NaN        NaN    NaN    NaN    NaN                       NaT        NaN        NaN       NaN       NaN          NaN          NaN             0 1.814318\n",
      "1983-03-31 22:00:00+00:00           NaN        NaN    NaN    NaN    NaN                       NaT        NaN        NaN       NaN       NaN          NaN          NaN             0 1.722520\n",
      "\n",
      "Wrote: hcast_event_to_ibtracs_matches.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\csherwood\\AppData\\Local\\Temp\\1\\ipykernel_7040\\3818482826.py:53: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"ISO_TIME\"] = pd.to_datetime(df[\"ISO_TIME\"], utc=True, errors=\"coerce\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# CO-OPS 8654467 (USCG Station Hatteras) location (deg)\n",
    "STATION_LAT = 35.208637\n",
    "STATION_LON = -75.70417\n",
    "\n",
    "RADIUS_KM = 100.0              # search radius for storm tracks\n",
    "TIME_WINDOW_DAYS = 2.0         # search +/- this many days around each event time\n",
    "MAX_MATCHES_PER_EVENT = 1      # return top N candidates per event (set 1 for only best)\n",
    "\n",
    "# IBTrACS source: North Atlantic v04r01 (CSV)\n",
    "IBTRACS_URL = \"https://www.ncei.noaa.gov/data/international-best-track-archive-for-climate-stewardship-ibtracs/v04r01/access/csv/ibtracs.NA.list.v04r01.csv\"\n",
    "IBTRACS_LOCAL = \"ibtracs.NA.list.v04r01.csv\"\n",
    "\n",
    "\n",
    "def haversine_km(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"Great-circle distance (km) between points.\"\"\"\n",
    "    R = 6371.0\n",
    "    lat1 = np.deg2rad(lat1); lon1 = np.deg2rad(lon1)\n",
    "    lat2 = np.deg2rad(lat2); lon2 = np.deg2rad(lon2)\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat/2.0)**2 + np.cos(lat1)*np.cos(lat2)*np.sin(dlon/2.0)**2\n",
    "    return 2.0 * R * np.arcsin(np.sqrt(a))\n",
    "\n",
    "def ensure_ibtracs_csv(url, local_path):\n",
    "    if os.path.exists(local_path) and os.path.getsize(local_path) > 0:\n",
    "        return local_path\n",
    "    print(f\"Downloading IBTrACS CSV -> {local_path} ...\")\n",
    "    r = requests.get(url, stream=True, timeout=300)\n",
    "    r.raise_for_status()\n",
    "    with open(local_path, \"wb\") as f:\n",
    "        for chunk in r.iter_content(chunk_size=1024*1024):\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "    return local_path\n",
    "\n",
    "def load_ibtracs_points(csv_path):\n",
    "    \"\"\"\n",
    "    Load a minimal set of IBTrACS columns needed for matching.\n",
    "    Column names come from IBTrACS v04r01 CSV documentation.\n",
    "    \"\"\"\n",
    "    usecols = [\n",
    "        \"SID\", \"NAME\", \"SEASON\", \"BASIN\", \"ISO_TIME\",\n",
    "        \"USA_LAT\", \"USA_LON\", \"USA_WIND\", \"USA_PRES\", \"NATURE\"\n",
    "    ]\n",
    "    df = pd.read_csv(csv_path, usecols=lambda c: c in usecols, low_memory=False)\n",
    "\n",
    "    # Parse and clean\n",
    "    df[\"ISO_TIME\"] = pd.to_datetime(df[\"ISO_TIME\"], utc=True, errors=\"coerce\")\n",
    "    df[\"USA_LAT\"] = pd.to_numeric(df[\"USA_LAT\"], errors=\"coerce\")\n",
    "    df[\"USA_LON\"] = pd.to_numeric(df[\"USA_LON\"], errors=\"coerce\")\n",
    "    df[\"USA_WIND\"] = pd.to_numeric(df.get(\"USA_WIND\"), errors=\"coerce\")\n",
    "    df[\"USA_PRES\"] = pd.to_numeric(df.get(\"USA_PRES\"), errors=\"coerce\")\n",
    "\n",
    "    df = df.dropna(subset=[\"ISO_TIME\", \"USA_LAT\", \"USA_LON\"])\n",
    "    # IBTrACS sometimes uses \"NOT NAMED\" or blanks; keep but label later\n",
    "    df[\"NAME\"] = df[\"NAME\"].fillna(\"\").astype(str).str.strip()\n",
    "    return df\n",
    "\n",
    "def match_events_to_ibtracs(event_times_utc, ib, lat0, lon0, radius_km=100, window_days=2, topn=1):\n",
    "    out_rows = []\n",
    "    dt = pd.Timedelta(days=float(window_days))\n",
    "\n",
    "    for t in pd.to_datetime(event_times_utc, utc=True):\n",
    "        t1, t2 = t - dt, t + dt\n",
    "        sub = ib[(ib[\"ISO_TIME\"] >= t1) & (ib[\"ISO_TIME\"] <= t2)].copy()\n",
    "        if len(sub) == 0:\n",
    "            out_rows.append(dict(event_time=t, n_candidates=0))\n",
    "            continue\n",
    "\n",
    "        # Distance to station for each best-track point\n",
    "        sub[\"dist_km\"] = haversine_km(lat0, lon0, sub[\"USA_LAT\"].values, sub[\"USA_LON\"].values)\n",
    "\n",
    "        # keep within radius\n",
    "        sub = sub[sub[\"dist_km\"] <= radius_km].copy()\n",
    "        if len(sub) == 0:\n",
    "            out_rows.append(dict(event_time=t, n_candidates=0))\n",
    "            continue\n",
    "\n",
    "        # Score: prioritize smallest distance, then smallest time offset\n",
    "        sub[\"dt_hours\"] = (sub[\"ISO_TIME\"] - t).abs() / pd.Timedelta(hours=1)\n",
    "        sub[\"score\"] = sub[\"dist_km\"] + 5.0 * sub[\"dt_hours\"]  # weight time offsets (tunable)\n",
    "\n",
    "        sub = sub.sort_values([\"score\", \"dist_km\", \"dt_hours\"]).head(int(topn))\n",
    "\n",
    "        for _, r in sub.iterrows():\n",
    "            name = r[\"NAME\"] if r[\"NAME\"] else \"UNNAMED\"\n",
    "            out_rows.append(dict(\n",
    "                event_time=t,\n",
    "                storm_sid=r.get(\"SID\", \"\"),\n",
    "                storm_name=name,\n",
    "                season=r.get(\"SEASON\", np.nan),\n",
    "                basin=r.get(\"BASIN\", \"\"),\n",
    "                nature=r.get(\"NATURE\", \"\"),\n",
    "                track_time=r[\"ISO_TIME\"],\n",
    "                storm_lat=r[\"USA_LAT\"],\n",
    "                storm_lon=r[\"USA_LON\"],\n",
    "                dist_km=float(r[\"dist_km\"]),\n",
    "                dt_hours=float(r[\"dt_hours\"]),\n",
    "                usa_wind_kt=r.get(\"USA_WIND\", np.nan),\n",
    "                usa_pres_mb=r.get(\"USA_PRES\", np.nan),\n",
    "                n_candidates=len(sub),\n",
    "            ))\n",
    "\n",
    "    return pd.DataFrame(out_rows)\n",
    "\n",
    "\n",
    "# Input event timews from hindcast peaks table:\n",
    "events = pd.read_csv( 'COOPS8654467_top20_hindcast_events_summary.csv' )\n",
    "event_times = pd.to_datetime(events[\"peak_time_utc\"], utc=True)\n",
    "\n",
    "csv_path = ensure_ibtracs_csv(IBTRACS_URL, IBTRACS_LOCAL)\n",
    "ib = load_ibtracs_points(csv_path)\n",
    "\n",
    "matches = match_events_to_ibtracs(\n",
    "    event_times_utc=event_times,\n",
    "    ib=ib,\n",
    "    lat0=STATION_LAT,\n",
    "    lon0=STATION_LON,\n",
    "    radius_km=RADIUS_KM,\n",
    "    window_days=TIME_WINDOW_DAYS,\n",
    "    topn=MAX_MATCHES_PER_EVENT\n",
    ")\n",
    "matches[\"peak_m\"] = events[\"wl_pred_peak_m\"]\n",
    "\n",
    "print(matches.head(20).to_string(index=False))\n",
    "\n",
    "# Optional: save results\n",
    "matches.to_csv(\"hcast_events_to_ibtracs_matches.csv\", index=False)\n",
    "print(\"\\nWrote: hcast_event_to_ibtracs_matches.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5d34647-3854-4078-a08e-455ee7575ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               event_time     storm_sid storm_name season  basin nature                track_time  storm_lat  storm_lon   dist_km  dt_hours  usa_wind_kt  usa_pres_mb  n_candidates  peak_m\n",
      "2016-10-09 10:00:00+00:00 2016273N13300    MATTHEW   2016    NaN     TS 2016-10-09 09:00:00+00:00       34.9      -75.3 50.311519       1.0         68.0        984.0             1   1.788\n",
      "2019-09-06 15:00:00+00:00 2019236N10314     DORIAN   2019    NaN     TS 2019-09-06 12:30:00+00:00       35.2      -75.6  9.513230       2.5         85.0        956.0             1   1.658\n",
      "2016-09-03 17:00:00+00:00 2016242N24279    HERMINE   2016    NaN     ET 2016-09-03 12:00:00+00:00       35.8      -75.5 68.304375       5.0         60.0        995.0             1   1.394\n",
      "2010-09-03 09:00:00+00:00           NaN        NaN    NaN    NaN    NaN                       NaT        NaN        NaN       NaN       NaN          NaN          NaN             0   1.267\n",
      "2012-10-29 03:00:00+00:00           NaN        NaN    NaN    NaN    NaN                       NaT        NaN        NaN       NaN       NaN          NaN          NaN             0   1.205\n",
      "\n",
      "Wrote: obs_events_to_ibtracs_matches.csv\n"
     ]
    }
   ],
   "source": [
    "# Top observed event times:\n",
    "\n",
    "event_times = [\"2016-10-09 10:00:00+00:00\",\n",
    "                \"2019-09-06 15:00:00+00:00\",\n",
    "                \"2016-09-03 17:00:00+00:00\",\n",
    "                \"2010-09-03 09:00:00+00:00\",\n",
    "                \"2012-10-29 03:00:00+00:00\"]\n",
    "obs_peak_m = [1.788, 1.658, 1.394, 1.267, 1.205]\n",
    "\n",
    "\n",
    "matches = match_events_to_ibtracs(\n",
    "    event_times_utc=event_times,\n",
    "    ib=ib,\n",
    "    lat0=STATION_LAT,\n",
    "    lon0=STATION_LON,\n",
    "    radius_km=RADIUS_KM,\n",
    "    window_days=TIME_WINDOW_DAYS,\n",
    "    topn=MAX_MATCHES_PER_EVENT\n",
    ")\n",
    "\n",
    "matches[\"peak_m\"] = pd.Series(obs_peak_m, dtype=float)\n",
    "\n",
    "print(matches.head(20).to_string(index=False))\n",
    "\n",
    "# Optional: save results\n",
    "matches.to_csv(\"obs_events_to_ibtracs_matches.csv\", index=False)\n",
    "print(\"\\nWrote: obs_events_to_ibtracs_matches.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

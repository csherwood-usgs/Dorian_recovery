{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5d3b6ca-0515-4ec2-a3bf-f26218170763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged file: isd_KHSE_only/KHSE_area_ISD_wind_merged.csv\n",
      "Rows: 623597\n",
      "Span: 1957-03-01 05:00:00+00:00 to 2025-08-27 04:59:00+00:00\n",
      "time dtype: datetime64[ns, UTC]\n",
      "time dtype (after): datetime64[ns, UTC]\n",
      "\n",
      "IDs present (usafwban) and record counts:\n",
      "usafwban\n",
      "72313993729    333084\n",
      "72304093729    198426\n",
      "99999993729     92087\n",
      "\n",
      "Sampled station metadata from raw files:\n",
      "   usafwban                 file     STATION                                      NAME  LATITUDE  LONGITUDE  ELEVATION        DATE_example\n",
      "72304093729 72304093729_1973.csv 72304093729 CAPE HATTERAS BILLY MITCHELL FIELD, NC US  35.23260  -75.62190        3.4 1973-01-01T00:00:00\n",
      "72304093729 72304093729_1984.csv 72304093729 CAPE HATTERAS BILLY MITCHELL FIELD, NC US  35.23260  -75.62190        3.4 1984-01-01T00:00:00\n",
      "72304093729 72304093729_1995.csv 72304093729 CAPE HATTERAS BILLY MITCHELL FIELD, NC US  35.23260  -75.62190        3.4 1995-01-01T00:00:00\n",
      "72313993729 72313993729_1996.csv 72313993729 CAPE HATTERAS BILLY MITCHELL FIELD, NC US  35.23260  -75.62190        3.4 1996-01-01T00:00:00\n",
      "72313993729 72313993729_2010.csv 72313993729 CAPE HATTERAS BILLY MITCHELL FIELD, NC US  35.23260  -75.62190        3.4 2010-01-01T00:51:00\n",
      "72313993729 72313993729_2025.csv 72313993729 CAPE HATTERAS BILLY MITCHELL FIELD, NC US  35.23238  -75.62223        3.8 2025-01-01T00:51:00\n",
      "99999993729 99999993729_1957.csv 99999993729 CAPE HATTERAS BILLY MITCHELL FIELD, NC US  35.23260  -75.62190        3.4 1957-03-01T05:00:00\n",
      "99999993729 99999993729_1964.csv 99999993729 CAPE HATTERAS BILLY MITCHELL FIELD, NC US  35.23260  -75.62190        3.4 1964-01-01T00:00:00\n",
      "99999993729 99999993729_1972.csv 99999993729 CAPE HATTERAS BILLY MITCHELL FIELD, NC US  35.23260  -75.62190        3.4 1972-01-01T00:00:00\n",
      "\n",
      "Uniqueness summary (1 = stable across sampled files):\n",
      "   usafwban  n_files  STATION_unique  NAME_unique  LAT_unique  LON_unique  ELEV_unique\n",
      "72304093729        3               1            1           1           1            1\n",
      "72313993729        3               1            1           2           2            2\n",
      "99999993729        3               1            1           1           1            1\n",
      "\n",
      "NOTE on wind height:\n",
      "Global-hourly access CSV does not reliably provide per-record anemometer height.\n",
      "For airport ASOS/AWOS winds, treating them as standard near-surface (often ~10 m) is common,\n",
      "but you should not assume an explicit, invariant sensor height without external station documentation.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "MERGED_CSV = \"isd_KHSE_only/KHSE_area_ISD_wind_merged.csv\"   # your merged winds\n",
    "RAW_DIR    = Path(\"isd_KHSE_only/raw\")                      # where station-year CSVs were saved\n",
    "SAMPLE_N_FILES_PER_ID = 3                                   # metadata sampling from raw files\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Read merged file and confirm time dtype\n",
    "# -----------------------------\n",
    "wind = pd.read_csv(MERGED_CSV, parse_dates=[\"time\"])\n",
    "wind = wind.sort_values(\"time\").reset_index(drop=True)\n",
    "\n",
    "print(\"Merged file:\", MERGED_CSV)\n",
    "print(\"Rows:\", len(wind))\n",
    "print(\"Span:\", wind[\"time\"].min(), \"to\", wind[\"time\"].max())\n",
    "print(\"time dtype:\", wind[\"time\"].dtype)\n",
    "\n",
    "# If time is timezone-naive, you can make it explicit UTC for consistency:\n",
    "if str(wind[\"time\"].dtype) == \"datetime64[ns]\":\n",
    "    wind[\"time\"] = wind[\"time\"].dt.tz_localize(\"UTC\")\n",
    "    print(\"-> localized merged time to UTC\")\n",
    "print(\"time dtype (after):\", wind[\"time\"].dtype)\n",
    "\n",
    "print(\"\\nIDs present (usafwban) and record counts:\")\n",
    "print(wind[\"usafwban\"].value_counts().to_string())\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Inspect station metadata from raw global-hourly station-year CSVs\n",
    "#    Global-hourly access CSVs often include columns like:\n",
    "#    STATION, NAME, LATITUDE, LONGITUDE, ELEVATION, DATE, WND, ...\n",
    "#    We'll sample a few files per usafwban and summarize unique values.\n",
    "# -----------------------------\n",
    "def find_station_year_files(raw_dir, usafwban):\n",
    "    return sorted(raw_dir.glob(f\"{usafwban}_*.csv\"))\n",
    "\n",
    "def read_station_metadata_one_file(csv_path):\n",
    "    # Read only header + first row to minimize I/O\n",
    "    df0 = pd.read_csv(csv_path, nrows=1, low_memory=False)\n",
    "    cols = {c.upper(): c for c in df0.columns}\n",
    "\n",
    "    def get_col(*names):\n",
    "        for n in names:\n",
    "            if n in cols:\n",
    "                return df0[cols[n]].iloc[0]\n",
    "        return np.nan\n",
    "\n",
    "    return {\n",
    "        \"file\": csv_path.name,\n",
    "        \"STATION\":   get_col(\"STATION\"),\n",
    "        \"NAME\":      get_col(\"NAME\", \"STATION NAME\"),\n",
    "        \"LATITUDE\":  get_col(\"LATITUDE\", \"LAT\"),\n",
    "        \"LONGITUDE\": get_col(\"LONGITUDE\", \"LON\"),\n",
    "        \"ELEVATION\": get_col(\"ELEVATION\", \"ELEV\", \"ELEV(M)\"),\n",
    "        \"DATE_example\": get_col(\"DATE\", \"DATE TIME\", \"DATETIME\"),\n",
    "    }\n",
    "\n",
    "meta_rows = []\n",
    "for usafwban in sorted(wind[\"usafwban\"].dropna().astype(str).unique()):\n",
    "    files = find_station_year_files(RAW_DIR, usafwban)\n",
    "    if not files:\n",
    "        print(f\"\\n[WARN] No raw files found for {usafwban} under {RAW_DIR}\")\n",
    "        continue\n",
    "\n",
    "    # sample a few files across the span (first/middle/last)\n",
    "    idx = np.unique(np.linspace(0, len(files)-1, min(SAMPLE_N_FILES_PER_ID, len(files))).astype(int))\n",
    "    for i in idx:\n",
    "        meta_rows.append({\"usafwban\": usafwban, **read_station_metadata_one_file(files[i])})\n",
    "\n",
    "meta = pd.DataFrame(meta_rows)\n",
    "\n",
    "print(\"\\nSampled station metadata from raw files:\")\n",
    "print(meta[[\"usafwban\",\"file\",\"STATION\",\"NAME\",\"LATITUDE\",\"LONGITUDE\",\"ELEVATION\",\"DATE_example\"]].to_string(index=False))\n",
    "\n",
    "# summarize uniqueness per usafwban\n",
    "def nunique_s(x): return pd.Series(x).dropna().astype(str).nunique()\n",
    "\n",
    "summary = meta.groupby(\"usafwban\").agg(\n",
    "    n_files=(\"file\",\"count\"),\n",
    "    STATION_unique=(\"STATION\", nunique_s),\n",
    "    NAME_unique=(\"NAME\", nunique_s),\n",
    "    LAT_unique=(\"LATITUDE\", nunique_s),\n",
    "    LON_unique=(\"LONGITUDE\", nunique_s),\n",
    "    ELEV_unique=(\"ELEVATION\", nunique_s),\n",
    ").reset_index()\n",
    "\n",
    "print(\"\\nUniqueness summary (1 = stable across sampled files):\")\n",
    "print(summary.to_string(index=False))\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Quick note on wind height\n",
    "# -----------------------------\n",
    "print(\"\\nNOTE on wind height:\")\n",
    "print(\"Global-hourly access CSV does not reliably provide per-record anemometer height.\")\n",
    "print(\"For airport ASOS/AWOS winds, treating them as standard near-surface (often ~10 m) is common,\")\n",
    "print(\"but you should not assume an explicit, invariant sensor height without external station documentation.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86b177ce-57e7-4637-a2b5-b4d4d6690589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               event_time     storm_sid storm_name season  basin nature                track_time  storm_lat  storm_lon   dist_km  dt_hours  usa_wind_kt  usa_pres_mb  n_candidates\n",
      "1958-09-28 04:00:00+00:00 1958264N17308     HELENE   1958    NaN     TS 1958-09-28 03:00:00+00:00       35.1      -74.9 74.100894       1.0        113.0        944.0             2\n",
      "1958-09-28 04:00:00+00:00 1958264N17308     HELENE   1958    NaN     TS 1958-09-28 00:00:00+00:00       34.7      -75.9 59.306909       4.0        115.0        938.0             2\n",
      "1980-03-25 02:00:00+00:00           NaN        NaN    NaN    NaN    NaN                       NaT        NaN        NaN       NaN       NaN          NaN          NaN             0\n",
      "1980-07-04 08:00:00+00:00           NaN        NaN    NaN    NaN    NaN                       NaT        NaN        NaN       NaN       NaN          NaN          NaN             0\n",
      "1979-12-02 04:00:00+00:00           NaN        NaN    NaN    NaN    NaN                       NaT        NaN        NaN       NaN       NaN          NaN          NaN             0\n",
      "1981-03-27 07:00:00+00:00           NaN        NaN    NaN    NaN    NaN                       NaT        NaN        NaN       NaN       NaN          NaN          NaN             0\n",
      "1993-08-31 22:00:00+00:00 1993235N20307      EMILY   1993    NaN     TS 1993-08-31 21:00:00+00:00       35.2      -75.1 54.901713       1.0        100.0        961.0             3\n",
      "1993-08-31 22:00:00+00:00 1993235N20307      EMILY   1993    NaN     TS 1993-09-01 00:00:00+00:00       35.6      -74.9 84.887286       2.0        100.0        960.0             3\n",
      "1993-08-31 22:00:00+00:00 1993235N20307      EMILY   1993    NaN     TS 1993-08-31 18:00:00+00:00       34.5      -75.2 91.242856       4.0        100.0        962.0             3\n",
      "1985-09-27 07:00:00+00:00 1985260N13336     GLORIA   1985    NaN     TS 1985-09-27 05:30:00+00:00       35.2      -75.6  9.513230       1.5         90.0        942.0             2\n",
      "1985-09-27 07:00:00+00:00 1985260N13336     GLORIA   1985    NaN     TS 1985-09-27 06:00:00+00:00       35.5      -75.5 37.315927       1.0         90.0        942.0             2\n",
      "1976-07-11 22:00:00+00:00           NaN        NaN    NaN    NaN    NaN                       NaT        NaN        NaN       NaN       NaN          NaN          NaN             0\n",
      "1981-06-16 02:00:00+00:00           NaN        NaN    NaN    NaN    NaN                       NaT        NaN        NaN       NaN       NaN          NaN          NaN             0\n",
      "2005-09-15 12:00:00+00:00 2005249N26281    OPHELIA   2005    NaN     TS 2005-09-15 12:00:00+00:00       34.7      -75.8 57.228187       0.0         65.0        984.0             3\n",
      "2005-09-15 12:00:00+00:00 2005249N26281    OPHELIA   2005    NaN     TS 2005-09-15 15:00:00+00:00       34.7      -75.7 56.559131       3.0         65.0        985.0             3\n",
      "2005-09-15 12:00:00+00:00 2005249N26281    OPHELIA   2005    NaN     TS 2005-09-15 18:00:00+00:00       34.7      -75.6 57.349100       6.0         65.0        986.0             3\n",
      "1961-04-13 04:00:00+00:00           NaN        NaN    NaN    NaN    NaN                       NaT        NaN        NaN       NaN       NaN          NaN          NaN             0\n",
      "1980-03-03 02:00:00+00:00           NaN        NaN    NaN    NaN    NaN                       NaT        NaN        NaN       NaN       NaN          NaN          NaN             0\n",
      "2003-09-18 15:00:00+00:00 2003249N14329     ISABEL   2003    NaN     TS 2003-09-18 17:00:00+00:00       34.9      -76.2 56.698778       2.0         90.0        957.0             3\n",
      "2003-09-18 15:00:00+00:00 2003249N14329     ISABEL   2003    NaN     TS 2003-09-18 18:00:00+00:00       35.1      -76.4 64.403182       3.0         85.0        958.0             3\n",
      "\n",
      "Wrote: event_to_ibtracs_matches.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\csherwood\\AppData\\Local\\Temp\\1\\ipykernel_7040\\2745560769.py:72: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"ISO_TIME\"] = pd.to_datetime(df[\"ISO_TIME\"], utc=True, errors=\"coerce\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# ============================================================\n",
    "# USER INPUTS\n",
    "# ============================================================\n",
    "# CO-OPS 8654467 (USCG Station Hatteras) location (deg)\n",
    "STATION_LAT = 35.208637\n",
    "STATION_LON = -75.70417\n",
    "\n",
    "RADIUS_KM = 100.0\n",
    "TIME_WINDOW_DAYS = 2.0         # search +/- this many days around each event time\n",
    "MAX_MATCHES_PER_EVENT = 3      # return top N candidates per event (set 1 for only best)\n",
    "\n",
    "# IBTrACS source: North Atlantic v04r01 (CSV)\n",
    "IBTRACS_URL = \"https://www.ncei.noaa.gov/data/international-best-track-archive-for-climate-stewardship-ibtracs/v04r01/access/csv/ibtracs.NA.list.v04r01.csv\"\n",
    "IBTRACS_LOCAL = \"ibtracs.NA.list.v04r01.csv\"\n",
    "\n",
    "# ============================================================\n",
    "# INPUT: EVENT TIMES\n",
    "# ============================================================\n",
    "# 1) From hindcast peaks table:\n",
    "events = pd.read_csv( 'COOPS8654467_top20_hindcast_events_summary.csv' )\n",
    "event_times = pd.to_datetime(events[\"peak_time_utc\"], utc=True)\n",
    "\n",
    "# 2) Top observed event times:\n",
    "'''\n",
    "event_times = [\"2016-10-09 10:00:00+00:00\",\n",
    "                \"2019-09-06 15:00:00+00:00\",\n",
    "               \"2016-09-03 17:00:00+00:00\",\"2010-09-03 09:00:00+00:00\",\n",
    "                 \"2012-10-29 03:00:00+00:00\"]\n",
    "'''\n",
    "# ============================================================\n",
    "# HELPERS\n",
    "# ============================================================\n",
    "def haversine_km(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"Great-circle distance (km) between points.\"\"\"\n",
    "    R = 6371.0\n",
    "    lat1 = np.deg2rad(lat1); lon1 = np.deg2rad(lon1)\n",
    "    lat2 = np.deg2rad(lat2); lon2 = np.deg2rad(lon2)\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat/2.0)**2 + np.cos(lat1)*np.cos(lat2)*np.sin(dlon/2.0)**2\n",
    "    return 2.0 * R * np.arcsin(np.sqrt(a))\n",
    "\n",
    "def ensure_ibtracs_csv(url, local_path):\n",
    "    if os.path.exists(local_path) and os.path.getsize(local_path) > 0:\n",
    "        return local_path\n",
    "    print(f\"Downloading IBTrACS CSV -> {local_path} ...\")\n",
    "    r = requests.get(url, stream=True, timeout=300)\n",
    "    r.raise_for_status()\n",
    "    with open(local_path, \"wb\") as f:\n",
    "        for chunk in r.iter_content(chunk_size=1024*1024):\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "    return local_path\n",
    "\n",
    "def load_ibtracs_points(csv_path):\n",
    "    \"\"\"\n",
    "    Load a minimal set of IBTrACS columns needed for matching.\n",
    "    Column names come from IBTrACS v04r01 CSV documentation.\n",
    "    \"\"\"\n",
    "    usecols = [\n",
    "        \"SID\", \"NAME\", \"SEASON\", \"BASIN\", \"ISO_TIME\",\n",
    "        \"USA_LAT\", \"USA_LON\", \"USA_WIND\", \"USA_PRES\", \"NATURE\"\n",
    "    ]\n",
    "    df = pd.read_csv(csv_path, usecols=lambda c: c in usecols, low_memory=False)\n",
    "\n",
    "    # Parse and clean\n",
    "    df[\"ISO_TIME\"] = pd.to_datetime(df[\"ISO_TIME\"], utc=True, errors=\"coerce\")\n",
    "    df[\"USA_LAT\"] = pd.to_numeric(df[\"USA_LAT\"], errors=\"coerce\")\n",
    "    df[\"USA_LON\"] = pd.to_numeric(df[\"USA_LON\"], errors=\"coerce\")\n",
    "    df[\"USA_WIND\"] = pd.to_numeric(df.get(\"USA_WIND\"), errors=\"coerce\")\n",
    "    df[\"USA_PRES\"] = pd.to_numeric(df.get(\"USA_PRES\"), errors=\"coerce\")\n",
    "\n",
    "    df = df.dropna(subset=[\"ISO_TIME\", \"USA_LAT\", \"USA_LON\"])\n",
    "    # IBTrACS sometimes uses \"NOT NAMED\" or blanks; keep but label later\n",
    "    df[\"NAME\"] = df[\"NAME\"].fillna(\"\").astype(str).str.strip()\n",
    "    return df\n",
    "\n",
    "def match_events_to_ibtracs(event_times_utc, ib, lat0, lon0, radius_km=100, window_days=2, topn=1):\n",
    "    out_rows = []\n",
    "    dt = pd.Timedelta(days=float(window_days))\n",
    "\n",
    "    for t in pd.to_datetime(event_times_utc, utc=True):\n",
    "        t1, t2 = t - dt, t + dt\n",
    "        sub = ib[(ib[\"ISO_TIME\"] >= t1) & (ib[\"ISO_TIME\"] <= t2)].copy()\n",
    "        if len(sub) == 0:\n",
    "            out_rows.append(dict(event_time=t, n_candidates=0))\n",
    "            continue\n",
    "\n",
    "        # Distance to station for each best-track point\n",
    "        sub[\"dist_km\"] = haversine_km(lat0, lon0, sub[\"USA_LAT\"].values, sub[\"USA_LON\"].values)\n",
    "\n",
    "        # keep within radius\n",
    "        sub = sub[sub[\"dist_km\"] <= radius_km].copy()\n",
    "        if len(sub) == 0:\n",
    "            out_rows.append(dict(event_time=t, n_candidates=0))\n",
    "            continue\n",
    "\n",
    "        # Score: prioritize smallest distance, then smallest time offset\n",
    "        sub[\"dt_hours\"] = (sub[\"ISO_TIME\"] - t).abs() / pd.Timedelta(hours=1)\n",
    "        sub[\"score\"] = sub[\"dist_km\"] + 5.0 * sub[\"dt_hours\"]  # weight time offsets (tunable)\n",
    "\n",
    "        sub = sub.sort_values([\"score\", \"dist_km\", \"dt_hours\"]).head(int(topn))\n",
    "\n",
    "        for _, r in sub.iterrows():\n",
    "            name = r[\"NAME\"] if r[\"NAME\"] else \"UNNAMED\"\n",
    "            out_rows.append(dict(\n",
    "                event_time=t,\n",
    "                storm_sid=r.get(\"SID\", \"\"),\n",
    "                storm_name=name,\n",
    "                season=r.get(\"SEASON\", np.nan),\n",
    "                basin=r.get(\"BASIN\", \"\"),\n",
    "                nature=r.get(\"NATURE\", \"\"),\n",
    "                track_time=r[\"ISO_TIME\"],\n",
    "                storm_lat=r[\"USA_LAT\"],\n",
    "                storm_lon=r[\"USA_LON\"],\n",
    "                dist_km=float(r[\"dist_km\"]),\n",
    "                dt_hours=float(r[\"dt_hours\"]),\n",
    "                usa_wind_kt=r.get(\"USA_WIND\", np.nan),\n",
    "                usa_pres_mb=r.get(\"USA_PRES\", np.nan),\n",
    "                n_candidates=len(sub),\n",
    "            ))\n",
    "\n",
    "    return pd.DataFrame(out_rows)\n",
    "\n",
    "# ============================================================\n",
    "# RUN\n",
    "# ============================================================\n",
    "if event_times is None:\n",
    "    raise ValueError(\"Set `event_times` to your event datetime list/Series first.\")\n",
    "\n",
    "csv_path = ensure_ibtracs_csv(IBTRACS_URL, IBTRACS_LOCAL)\n",
    "ib = load_ibtracs_points(csv_path)\n",
    "\n",
    "matches = match_events_to_ibtracs(\n",
    "    event_times_utc=event_times,\n",
    "    ib=ib,\n",
    "    lat0=STATION_LAT,\n",
    "    lon0=STATION_LON,\n",
    "    radius_km=RADIUS_KM,\n",
    "    window_days=TIME_WINDOW_DAYS,\n",
    "    topn=MAX_MATCHES_PER_EVENT\n",
    ")\n",
    "\n",
    "print(matches.head(20).to_string(index=False))\n",
    "\n",
    "# Optional: save results\n",
    "matches.to_csv(\"event_to_ibtracs_matches.csv\", index=False)\n",
    "print(\"\\nWrote: event_to_ibtracs_matches.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

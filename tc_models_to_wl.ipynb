{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d55a73c7-30d0-4c03-a863-c0e79fe25855",
   "metadata": {},
   "source": [
    "### Find TCs for a list of sites and compute water levels\n",
    "This might be a useful screening model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95f4cd97-b442-46e9-b9f6-f8356fbae7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\csherwood\\AppData\\Local\\Temp\\1\\ipykernel_33292\\3953066840.py:151: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[TIME_COL] = pd.to_datetime(df[TIME_COL], utc=True, errors=\"coerce\")\n",
      "C:\\Users\\csherwood\\AppData\\Local\\Temp\\1\\ipykernel_33292\\3953066840.py:181: FutureWarning: The behavior of DatetimeProperties.to_pydatetime is deprecated, in a future version this will return a Series containing python datetime objects instead of an ndarray. To retain the old behavior, call `np.array` on the result\n",
      "  u_tr, v_tr = storm_translation_uv(storm_df[TIME_COL].dt.to_pydatetime(), lat, lon)\n",
      "C:\\Users\\csherwood\\AppData\\Local\\Temp\\1\\ipykernel_33292\\3953066840.py:181: FutureWarning: The behavior of DatetimeProperties.to_pydatetime is deprecated, in a future version this will return a Series containing python datetime objects instead of an ndarray. To retain the old behavior, call `np.array` on the result\n",
      "  u_tr, v_tr = storm_translation_uv(storm_df[TIME_COL].dt.to_pydatetime(), lat, lon)\n",
      "C:\\Users\\csherwood\\AppData\\Local\\Temp\\1\\ipykernel_33292\\3953066840.py:181: FutureWarning: The behavior of DatetimeProperties.to_pydatetime is deprecated, in a future version this will return a Series containing python datetime objects instead of an ndarray. To retain the old behavior, call `np.array` on the result\n",
      "  u_tr, v_tr = storm_translation_uv(storm_df[TIME_COL].dt.to_pydatetime(), lat, lon)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: sites_rmw_crossings_setup_events.csv\n",
      "     site_id  site_lat  site_lon     L_m  h_m     storm_sid storm_name season  basin                      cross_time_utc   U10_mps  wind_dir_from_deg  eta_setup_m    dist_km     rmw_km   vmax_kt\n",
      "E. Matagorda   28.7039  -95.8407 70000.0  4.0 2001157N28265    ALLISON   2001    NaN 2001-06-06 00:37:54.004075960+00:00 22.357142         132.986737     1.591948  92.600000  92.600000 43.526108\n",
      "E. Matagorda   28.7039  -95.8407 70000.0  4.0 2002249N28266        FAY   2002    NaN 2002-09-07 06:31:55.863992477+00:00 19.132661         243.921514     1.165862  67.448282  67.448282 50.000000\n",
      "E. Matagorda   28.7039  -95.8407 70000.0  4.0 2002249N28266        FAY   2002    NaN 2002-09-07 10:48:08.475482642+00:00 17.728976          32.462864     1.001068  87.424574  87.424574 37.984305\n",
      "E. Matagorda   28.7039  -95.8407 70000.0  4.0 2003243N24268      GRACE   2003    NaN 2003-08-31 08:12:04.537840971+00:00 24.346067         205.390658     1.887791 123.854964 123.854964 35.000000\n",
      "E. Matagorda   28.7039  -95.8407 70000.0  4.0 2017228N14314     HARVEY   2017    NaN 2017-08-27 11:23:00.227650195+00:00 17.198803          11.988193     0.942091 169.974006 169.974006 35.616603\n",
      "E. Matagorda   28.7039  -95.8407 70000.0  4.0 2017228N14314     HARVEY   2017    NaN 2017-08-29 06:56:31.940242793+00:00 19.777473         220.689522     1.245770 111.120000 111.120000 40.000000\n",
      "E. Matagorda   28.7039  -95.8407 70000.0  4.0 2019261N28264     IMELDA   2019    NaN 2019-09-17 17:31:11.276089563+00:00 28.159221         164.693032     2.525443  47.075150  47.075150 39.581453\n",
      "E. Matagorda   28.7039  -95.8407 70000.0  4.0 2019261N28264     IMELDA   2019    NaN 2019-09-18 16:11:00.984808982+00:00 12.720926         115.471046     0.515387 214.137760 214.137760 30.000000\n",
      "E. Matagorda   28.7039  -95.8407 70000.0  4.0 2019261N28264     IMELDA   2019    NaN 2019-09-18 20:59:07.018121205+00:00 13.556623         123.757461     0.585328 250.020000 250.020000 28.009811\n",
      "E. Matagorda   28.7039  -95.8407 70000.0  4.0 2020261N21265       BETA   2020    NaN 2020-09-21 11:17:38.971303491+00:00 18.963029         243.441652     1.145280 111.120000 111.120000 45.000000\n",
      "E. Matagorda   28.7039  -95.8407 70000.0  4.0 2020261N21265       BETA   2020    NaN 2020-09-21 21:41:35.338470963+00:00 18.900941         303.960464     1.137793  65.521913  65.521913 43.462100\n",
      "E. Matagorda   28.7039  -95.8407 70000.0  4.0 2020261N21265       BETA   2020    NaN 2020-09-22 17:29:48.773498572+00:00 11.471274           6.739256     0.419102  70.974082  70.974082 25.838531\n",
      "E. Matagorda   28.7039  -95.8407 70000.0  4.0 2020261N21265       BETA   2020    NaN 2020-09-23 04:29:15.467924295+00:00 10.922067         133.384680     0.379932  74.080000  74.080000 25.000000\n",
      "E. Matagorda   28.7039  -95.8407 70000.0  4.0 2021256N21265   NICHOLAS   2021    NaN 2021-09-14 03:24:27.103698841+00:00 31.758928         265.386210     3.212388  40.140205  40.140205 65.000000\n",
      "E. Matagorda   28.7039  -95.8407 70000.0  4.0 2021256N21265   NICHOLAS   2021    NaN 2021-09-14 19:49:02.352205877+00:00 15.397871         143.816632     0.755123 148.160000 148.160000 33.788453\n",
      "E. Matagorda   28.7039  -95.8407 70000.0  4.0 2024181N09320      BERYL   2024    NaN 2024-07-08 06:43:25.067390359+00:00 32.413749         271.835887     3.346222  46.300000  46.300000 72.713612\n",
      "E. Matagorda   28.7039  -95.8407 70000.0  4.0 2024181N09320      BERYL   2024    NaN 2024-07-08 11:10:05.581139243+00:00 31.613500          82.455232     3.183035  53.506050  53.506050 72.495349\n",
      "   Galveston   39.3966  -94.8340 70000.0  4.0 2020154N19269  CRISTOBAL   2020    NaN 2020-06-09 10:54:23.456670509+00:00 20.935337         203.772954     1.395906 314.840000 314.840000 25.000000\n",
      "   Galveston   39.3966  -94.8340 70000.0  4.0 2020154N19269  CRISTOBAL   2020    NaN 2020-06-09 18:59:58.959487574+00:00 23.212202         172.407050     1.716046 314.840000 314.840000 30.000000\n",
      "     Pamlico   35.2530  -75.7000 85000.0  4.0 2002196N34283     ARTHUR   2002    NaN 2002-07-14 20:38:08.237688336+00:00 19.134077         277.377753     1.415899  74.080000  74.080000 30.000000\n",
      "     Pamlico   35.2530  -75.7000 85000.0  4.0 2002196N34283     ARTHUR   2002    NaN 2002-07-15 00:34:48.545079955+00:00 19.550788         214.324990     1.478243  75.870734  75.870734 30.580151\n",
      "     Pamlico   35.2530  -75.7000 85000.0  4.0 2002252N29289     GUSTAV   2002    NaN 2002-09-10 17:01:23.177891935+00:00 27.614255         236.803996     2.949061  58.575349  58.575349 54.348737\n",
      "     Pamlico   35.2530  -75.7000 85000.0  4.0 2002252N29289     GUSTAV   2002    NaN 2002-09-10 21:35:54.659886713+00:00 29.056925         187.486079     3.265250  55.560000  55.560000 55.000000\n",
      "     Pamlico   35.2530  -75.7000 85000.0  4.0 2002264N28308       KYLE   2002    NaN 2002-10-12 03:37:44.875337901+00:00 17.144913         304.876279     1.136810 106.786554 106.786554 36.048553\n",
      "     Pamlico   35.2530  -75.7000 85000.0  4.0 2002264N28308       KYLE   2002    NaN 2002-10-12 06:59:26.767891023+00:00 15.615160         135.982581     0.942996  55.560000  55.560000 40.000000\n",
      "\n",
      "Total events: 65\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# ============================================================\n",
    "# USER INPUT: SITES TABLE (EDIT THIS)\n",
    "# ============================================================\n",
    "# L_m = effective fetch (m)\n",
    "# h_m = representative depth (m)\n",
    "sites = pd.DataFrame([\n",
    "    dict(site_id=\"site1\", lat=35.21, lon=-75.70, L_m=60e3, h_m=4.0),\n",
    "    # dict(site_id=\"site2\", lat=..., lon=..., L_m=..., h_m=...),\n",
    "])\n",
    "\n",
    "sites = pd.DataFrame( [ dict( site_id = \"Pamlico\", lat=35.253,   lon=-75.70,  L_m=85e3, h_m=4.0), \n",
    "            dict( site_id = \"Galveston\", lat=39.3966, lon=-94.834, L_m=70e3,  h_m=4.0 ), \n",
    "             dict( site_id = \"E. Matagorda\", lat=28.7039, lon=-95.8407, L_m=70e3,  h_m=4.0 )] )\n",
    "\n",
    "# ============================================================\n",
    "# IBTRACS INPUT\n",
    "# ============================================================\n",
    "IBTRACS_URL = \"https://www.ncei.noaa.gov/data/international-best-track-archive-for-climate-stewardship-ibtracs/v04r01/access/csv/ibtracs.NA.list.v04r01.csv\"\n",
    "IBTRACS_LOCAL = \"ibtracs.NA.list.v04r01.csv\"\n",
    "\n",
    "# Which agency-specific fields to use\n",
    "LAT_COL = \"USA_LAT\"\n",
    "LON_COL = \"USA_LON\"\n",
    "WIND_COL = \"USA_WIND\"    # knots\n",
    "RMW_COL  = \"USA_RMW\"     # nautical miles in IBTrACS list files\n",
    "NAME_COL = \"NAME\"\n",
    "SID_COL  = \"SID\"\n",
    "TIME_COL = \"ISO_TIME\"\n",
    "\n",
    "# ============================================================\n",
    "# CROSSING DETECTION SETTINGS\n",
    "# ============================================================\n",
    "# crossing tolerance (km) for final screening\n",
    "CROSS_TOL_KM = 25.0\n",
    "\n",
    "# require storm to be tropical/subtropical? (set None to ignore)\n",
    "# NATURE in IBTrACS often includes: TS, HU, TY, etc. Can be messy across agencies.\n",
    "NATURE_ALLOW = None  # e.g. {\"TS\",\"HU\"} or None\n",
    "\n",
    "# ============================================================\n",
    "# SIMPLE CYCLONE WIND MODEL SETTINGS\n",
    "# ============================================================\n",
    "# Modified Rankine exponent outside RMW\n",
    "ALPHA_OUT = 0.5\n",
    "\n",
    "# Reduce gradient/track winds to 10 m? (simple scalar)\n",
    "V10_FACTOR = 0.90\n",
    "\n",
    "# Translation wind multiplier (adds some asymmetry)\n",
    "TRANS_FACTOR = 1.00\n",
    "\n",
    "# ============================================================\n",
    "# SETUP MODEL SETTINGS\n",
    "# ============================================================\n",
    "rho_air = 1.22\n",
    "rho_w   = 1025.0\n",
    "g_accel   = 9.81\n",
    "Cd      = 1.5e-3  # best-guess; you can make Cd a function of speed if desired\n",
    "\n",
    "# ============================================================\n",
    "# HELPERS\n",
    "# ============================================================\n",
    "def ensure_file(url, path):\n",
    "    if os.path.exists(path) and os.path.getsize(path) > 0:\n",
    "        return path\n",
    "    print(f\"Downloading {url} -> {path}\")\n",
    "    r = requests.get(url, stream=True, timeout=300)\n",
    "    r.raise_for_status()\n",
    "    with open(path, \"wb\") as f:\n",
    "        for chunk in r.iter_content(chunk_size=1024*1024):\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "    return path\n",
    "\n",
    "def haversine_km(lat1, lon1, lat2, lon2):\n",
    "    R = 6371.0\n",
    "    lat1 = np.deg2rad(lat1); lon1 = np.deg2rad(lon1)\n",
    "    lat2 = np.deg2rad(lat2); lon2 = np.deg2rad(lon2)\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat/2.0)**2 + np.cos(lat1)*np.cos(lat2)*np.sin(dlon/2.0)**2\n",
    "    return 2.0 * R * np.arcsin(np.sqrt(a))\n",
    "\n",
    "def bearing_deg(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"Bearing from (lat1,lon1) to (lat2,lon2), deg clockwise from north.\"\"\"\n",
    "    phi1 = np.deg2rad(lat1); phi2 = np.deg2rad(lat2)\n",
    "    dlon = np.deg2rad(lon2 - lon1)\n",
    "    y = np.sin(dlon) * np.cos(phi2)\n",
    "    x = np.cos(phi1)*np.sin(phi2) - np.sin(phi1)*np.cos(phi2)*np.cos(dlon)\n",
    "    brg = (np.rad2deg(np.arctan2(y, x)) + 360.0) % 360.0\n",
    "    return brg\n",
    "\n",
    "def uv_from_speed_dir_to(U, dir_to_deg):\n",
    "    th = np.deg2rad(dir_to_deg % 360.0)\n",
    "    u = U * np.sin(th)  # east\n",
    "    v = U * np.cos(th)  # north\n",
    "    return u, v\n",
    "\n",
    "def speed_dirfrom_from_uv(u, v):\n",
    "    U = np.sqrt(u*u + v*v)\n",
    "    dir_to = (np.rad2deg(np.arctan2(u, v)) + 360.0) % 360.0\n",
    "    dir_from = (dir_to + 180.0) % 360.0\n",
    "    return U, dir_from\n",
    "\n",
    "def modified_rankine(site_dist_km, rmw_km, vmax_ms, alpha_out=0.5):\n",
    "    \"\"\"Tangential wind magnitude at radius r using modified Rankine vortex.\"\"\"\n",
    "    r = max(site_dist_km, 1e-6)\n",
    "    R = max(rmw_km, 1e-6)\n",
    "    if r <= R:\n",
    "        V = vmax_ms * (r / R)\n",
    "    else:\n",
    "        V = vmax_ms * (R / r) ** alpha_out\n",
    "    return V\n",
    "\n",
    "def storm_translation_uv(track_times, track_lat, track_lon):\n",
    "    \"\"\"Compute translation vector between consecutive track points (m/s) using great-circle distance.\"\"\"\n",
    "    # forward differences; last point repeats\n",
    "    u = np.full(len(track_times), np.nan)\n",
    "    v = np.full(len(track_times), np.nan)\n",
    "    for i in range(len(track_times)-1):\n",
    "        dt = (track_times[i+1] - track_times[i]).total_seconds()\n",
    "        if not np.isfinite(dt) or dt <= 0:\n",
    "            continue\n",
    "        # distance and bearing from point i to i+1\n",
    "        d_km = haversine_km(track_lat[i], track_lon[i], track_lat[i+1], track_lon[i+1])\n",
    "        brg = bearing_deg(track_lat[i], track_lon[i], track_lat[i+1], track_lon[i+1])\n",
    "        # convert to m/s\n",
    "        spd = (d_km * 1000.0) / dt\n",
    "        uu, vv = uv_from_speed_dir_to(spd, brg)\n",
    "        u[i] = uu\n",
    "        v[i] = vv\n",
    "    # fill last with previous\n",
    "    u[-1] = u[-2]\n",
    "    v[-1] = v[-2]\n",
    "    return u, v\n",
    "\n",
    "def setup_eta_m(U10_ms, L_m, h_m, Cd=1.5e-3, g_accel=9.81):\n",
    "    tau = rho_air * Cd * U10_ms**2\n",
    "    return (tau * L_m) / (rho_w * g_accel * h_m)\n",
    "\n",
    "def load_ibtracs_list(path):\n",
    "    # Usecols: minimal plus wind structure\n",
    "    usecols = [SID_COL, NAME_COL, \"SEASON\", \"BASIN\", TIME_COL, \"NATURE\",\n",
    "               LAT_COL, LON_COL, WIND_COL, RMW_COL]\n",
    "    df = pd.read_csv(path, usecols=lambda c: c in usecols, low_memory=False)\n",
    "    df[TIME_COL] = pd.to_datetime(df[TIME_COL], utc=True, errors=\"coerce\")\n",
    "    for c in [LAT_COL, LON_COL, WIND_COL, RMW_COL]:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "    df[NAME_COL] = df[NAME_COL].fillna(\"\").astype(str).str.strip()\n",
    "    df = df.dropna(subset=[SID_COL, TIME_COL, LAT_COL, LON_COL])\n",
    "    return df\n",
    "\n",
    "def find_rmw_crossings_for_site(storm_df, site_lat, site_lon, tol_km=25.0):\n",
    "    \"\"\"\n",
    "    Given a single storm's track dataframe, return list of crossing records\n",
    "    where distance to site crosses RMW.\n",
    "    \"\"\"\n",
    "    storm_df = storm_df.sort_values(TIME_COL).copy()\n",
    "    t = storm_df[TIME_COL].to_list()\n",
    "    lat = storm_df[LAT_COL].values\n",
    "    lon = storm_df[LON_COL].values\n",
    "\n",
    "    # RMW in IBTrACS list typically in nautical miles; convert to km\n",
    "    rmw_nm = storm_df[RMW_COL].values.astype(float)\n",
    "    rmw_km = rmw_nm * 1.852\n",
    "\n",
    "    # If no RMW, nothing to do\n",
    "    if np.all(~np.isfinite(rmw_km)):\n",
    "        return []\n",
    "\n",
    "    # Distance from center to site\n",
    "    d_km = haversine_km(site_lat, site_lon, lat, lon)\n",
    "    x = d_km - rmw_km  # crossing when x changes sign\n",
    "\n",
    "    # translation vectors (m/s)\n",
    "    u_tr, v_tr = storm_translation_uv(storm_df[TIME_COL].dt.to_pydatetime(), lat, lon)\n",
    "\n",
    "    out = []\n",
    "    for i in range(len(storm_df)-1):\n",
    "        if not (np.isfinite(x[i]) and np.isfinite(x[i+1]) and np.isfinite(rmw_km[i]) and np.isfinite(rmw_km[i+1])):\n",
    "            continue\n",
    "\n",
    "        # sign change (including exact)\n",
    "        if x[i] == 0 or x[i+1] == 0 or (x[i] < 0 and x[i+1] > 0) or (x[i] > 0 and x[i+1] < 0):\n",
    "            # linear interpolation fraction\n",
    "            denom = (x[i+1] - x[i])\n",
    "            f = 0.0 if denom == 0 else (-x[i] / denom)\n",
    "            f = min(max(f, 0.0), 1.0)\n",
    "\n",
    "            t_cross = storm_df.iloc[i][TIME_COL] + (storm_df.iloc[i+1][TIME_COL] - storm_df.iloc[i][TIME_COL]) * f\n",
    "            rmw_cross_km = rmw_km[i] + (rmw_km[i+1] - rmw_km[i]) * f\n",
    "            d_cross_km = d_km[i] + (d_km[i+1] - d_km[i]) * f\n",
    "\n",
    "            # final tolerance check\n",
    "            if abs(d_cross_km - rmw_cross_km) > tol_km:\n",
    "                continue\n",
    "\n",
    "            # interpolate vmax and translation\n",
    "            vmax_kt = storm_df.iloc[i][WIND_COL]\n",
    "            vmax2_kt = storm_df.iloc[i+1][WIND_COL]\n",
    "            vmax_kt = np.nan if not np.isfinite(vmax_kt) else vmax_kt\n",
    "            vmax2_kt = np.nan if not np.isfinite(vmax2_kt) else vmax2_kt\n",
    "            vmax_cross_kt = vmax_kt + (vmax2_kt - vmax_kt) * f if (np.isfinite(vmax_kt) and np.isfinite(vmax2_kt)) else np.nan\n",
    "\n",
    "            # if vmax missing, you may choose to skip\n",
    "            if not np.isfinite(vmax_cross_kt):\n",
    "                continue\n",
    "\n",
    "            vmax_ms = vmax_cross_kt * 0.514444\n",
    "\n",
    "            # storm center at crossing (interp)\n",
    "            latc = lat[i] + (lat[i+1] - lat[i]) * f\n",
    "            lonc = lon[i] + (lon[i+1] - lon[i]) * f\n",
    "\n",
    "            # bearing from center to site\n",
    "            brg_cs = bearing_deg(latc, lonc, site_lat, site_lon)\n",
    "\n",
    "            # Tangential wind direction \"to\" for NH cyclones: 90 deg left of radial? (counterclockwise)\n",
    "            # If radial is from center to site (brg_cs), tangential \"to\" is brg_cs + 90 (counterclockwise circulation gives flow to the left of radial outward)\n",
    "            # This convention is a simplification; adjust if you want right/left based on hemisphere/basin.\n",
    "            dir_to_tan = (brg_cs + 90.0) % 360.0\n",
    "\n",
    "            # Tangential speed from modified Rankine at r = site distance\n",
    "            Vtan = modified_rankine(d_cross_km, rmw_cross_km, vmax_ms, alpha_out=ALPHA_OUT)\n",
    "\n",
    "            # Translation at crossing (interp)\n",
    "            u_trc = u_tr[i] + (u_tr[i+1] - u_tr[i]) * f if (np.isfinite(u_tr[i]) and np.isfinite(u_tr[i+1])) else u_tr[i]\n",
    "            v_trc = v_tr[i] + (v_tr[i+1] - v_tr[i]) * f if (np.isfinite(v_tr[i]) and np.isfinite(v_tr[i+1])) else v_tr[i]\n",
    "\n",
    "            # Combine vectors\n",
    "            u_tan, v_tan = uv_from_speed_dir_to(Vtan, dir_to_tan)\n",
    "            u_site = u_tan + TRANS_FACTOR * u_trc\n",
    "            v_site = v_tan + TRANS_FACTOR * v_trc\n",
    "\n",
    "            # Reduce to 10 m if desired\n",
    "            u_site *= V10_FACTOR\n",
    "            v_site *= V10_FACTOR\n",
    "\n",
    "            U10, Dfrom = speed_dirfrom_from_uv(u_site, v_site)\n",
    "\n",
    "            out.append(dict(\n",
    "                cross_time_utc=t_cross,\n",
    "                center_lat=latc, center_lon=lonc,\n",
    "                dist_km=float(d_cross_km),\n",
    "                rmw_km=float(rmw_cross_km),\n",
    "                vmax_kt=float(vmax_cross_kt),\n",
    "                U10_mps=float(U10),\n",
    "                wind_dir_from_deg=float(Dfrom),\n",
    "            ))\n",
    "\n",
    "    return out\n",
    "\n",
    "# ============================================================\n",
    "# RUN\n",
    "# ============================================================\n",
    "ensure_file(IBTRACS_URL, IBTRACS_LOCAL)\n",
    "ib = load_ibtracs_list(IBTRACS_LOCAL)\n",
    "\n",
    "results = []\n",
    "\n",
    "for _, site in sites.iterrows():\n",
    "    sid = site[\"site_id\"]\n",
    "    lat0 = float(site[\"lat\"]); lon0 = float(site[\"lon\"])\n",
    "    L_m  = float(site[\"L_m\"]);  h_m  = float(site[\"h_m\"])\n",
    "\n",
    "    # Loop storms by SID; for speed you can pre-filter by basin, season, etc.\n",
    "    for storm_sid, g_check in ib.groupby(SID_COL, sort=False):\n",
    "        if NATURE_ALLOW is not None:\n",
    "            # keep only points where NATURE is in allowed set\n",
    "            g2 = g_check[g_check[\"NATURE\"].astype(str).isin(NATURE_ALLOW)]\n",
    "            if len(g2) == 0:\n",
    "                continue\n",
    "            g_use = g2\n",
    "        else:\n",
    "            g_use = g_check\n",
    "\n",
    "        # Must have at least some RMW and wind\n",
    "        if g_use[RMW_COL].notna().sum() < 2 or g_use[WIND_COL].notna().sum() < 2:\n",
    "            continue\n",
    "\n",
    "        crossings = find_rmw_crossings_for_site(g_use, lat0, lon0, tol_km=CROSS_TOL_KM)\n",
    "        if not crossings:\n",
    "            continue\n",
    "\n",
    "        storm_name = (g_use[NAME_COL].iloc[0] if len(g_use) else \"\")\n",
    "        season = g_use.get(\"SEASON\", pd.Series([np.nan])).iloc[0]\n",
    "        basin  = g_use.get(\"BASIN\",  pd.Series([\"\"])).iloc[0]\n",
    "\n",
    "        for cr in crossings:\n",
    "            eta = setup_eta_m(float(cr[\"U10_mps\"]), L_m=float(L_m), h_m=float(h_m), Cd=float(Cd))\n",
    "            results.append(dict(\n",
    "                site_id=sid,\n",
    "                site_lat=lat0, site_lon=lon0,\n",
    "                L_m=L_m, h_m=h_m,\n",
    "                storm_sid=storm_sid,\n",
    "                storm_name=(storm_name if storm_name else \"UNNAMED\"),\n",
    "                season=season,\n",
    "                basin=basin,\n",
    "                cross_time_utc=cr[\"cross_time_utc\"],\n",
    "                U10_mps=float(cr[\"U10_mps\"]),\n",
    "                wind_dir_from_deg=float(cr[\"wind_dir_from_deg\"]),\n",
    "                eta_setup_m=float(eta),\n",
    "                dist_km=float(cr[\"dist_km\"]),\n",
    "                rmw_km=float(cr[\"rmw_km\"]),\n",
    "                vmax_kt=float(cr[\"vmax_kt\"]),\n",
    "            ))\n",
    "\n",
    "out = pd.DataFrame(results).sort_values([\"site_id\",\"cross_time_utc\"])\n",
    "out.to_csv(\"sites_rmw_crossings_setup_events.csv\", index=False)\n",
    "\n",
    "print(\"Wrote: sites_rmw_crossings_setup_events.csv\")\n",
    "print(out.head(25).to_string(index=False))\n",
    "print(\"\\nTotal events:\", len(out))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61fba1a4-9424-4770-8ad5-b3bb42213725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site_id</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>L_m</th>\n",
       "      <th>h_m</th>\n",
       "      <th>side_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pamlico</td>\n",
       "      <td>35.2530</td>\n",
       "      <td>-75.7000</td>\n",
       "      <td>85000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>39.3966</td>\n",
       "      <td>-94.8340</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Galveston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>28.7039</td>\n",
       "      <td>-95.8407</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>E. Matagorda</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   site_id      lat      lon      L_m  h_m       side_id\n",
       "0  Pamlico  35.2530 -75.7000  85000.0  4.0           NaN\n",
       "1      NaN  39.3966 -94.8340  70000.0  4.0     Galveston\n",
       "2      NaN  28.7039 -95.8407  70000.0  4.0  E. Matagorda"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sites"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
